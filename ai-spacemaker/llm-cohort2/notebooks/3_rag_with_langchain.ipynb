{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI-Maker-Space/LLM-Ops-Vault/blob/main/Week%201/First%20Session/Barbie_Retrieval_Augmented_Question_Answering_(RAQA)_Assignment%20(Completed).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLi09z_3qW8O"
      },
      "source": [
        "# Questioning Barbie Reviews with RAQA (Retrieval Augmented Question Answering)\n",
        "\n",
        "In the following notebook, you are tasked with creating a system that answers questions based on information found in reviews of the 2023 Barbie movie.\n",
        "\n",
        "## Build ðŸ—ï¸\n",
        "\n",
        "There are 3 main tasks in this notebook:\n",
        "\n",
        "1. Obtain and parse reviews from a review website\n",
        "2. Create a Vectorstore from the reviews\n",
        "3. Create a `RetrievalQA` chain \n",
        "\n",
        "## Ship ðŸš¢\n",
        "\n",
        "Create a Hugging Face Space that hosts your application.\n",
        "\n",
        "## Share ðŸš€\n",
        "\n",
        "Make a social media post about your final application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BBraMxjrwOx"
      },
      "source": [
        ">### Why RAQA and not RAG?\n",
        ">If we look at the original [paper](https://arxiv.org/abs/2005.11401), we find that RAG is a fairly specific and well defined term that isn't exactly the same as \"retrieve context, feed context to model in the prompt\".\n",
        ">For that reason, we're making the decision to delineate between \"actual\" RAG, and Retrieval Augmented Question Answering - which is not a well defined phrase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcL8585DsZML"
      },
      "source": [
        "### Pre-task Work\n",
        "\n",
        "All we really need to do to get started is to get our prerequisites!\n",
        "\n",
        "We'll be leveraging `langchain`, `openai`, and `pinecone` today.\n",
        "\n",
        "Check out the docs:\n",
        "- [LangChain](https://docs.langchain.com/docs/)\n",
        "- [OpenAI](https://github.com/openai/openai-python)\n",
        "- [Pinecone](https://docs.pinecone.io/docs/overview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "vQa6rjDLqPCI"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U openai langchain \"pinecone-client[grpc]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wF8_ODX5h-P",
        "outputId": "f3395c72-029b-4e49-f0b9-aba7e3c2195f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Open AI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Pinecone API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"PINECONE_ENV\"] = getpass.getpass(\"Pinecone Environment:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLrL342RtWxf"
      },
      "source": [
        "### Task 1: Data Preparation\n",
        "\n",
        "In this task we'll be collecting, and then parsing, our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh8QTtMhzY_g"
      },
      "source": [
        "#### Scraping IMDB Reviews of Barbie\n",
        "\n",
        "We'll use some Selenium based trickery to get the reviews we need to make our application.\n",
        "\n",
        "Check out the docs here:\n",
        "- [Selenium](https://www.selenium.dev/documentation/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "PsGPV2zHuCj2"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCNCZdzrw81B",
        "outputId": "f74cc223-af93-491a-e92e-5d7ee1355d49"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U scrapy selenium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You will need to install the `chromium-chromedriver` in order to use the method presented. \n",
        "\n",
        "`!apt install chromium-chromedriver` will install the chromedriver. \n",
        "\n",
        "You may have to use your terminal if you receive an error related to `sudo`. In that case, please use (in your terminal) `sudo apt install chromium-chromedriver`.\n",
        "\n",
        "Otherwise, the `.csv` is provided and can be loaded through `pandas` if you're experiencing issues relating to the web-scraping portion of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Niq6DKMOwPIn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scrapy.selector import Selector\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "k9AA_f-DxGyv"
      },
      "outputs": [],
      "source": [
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome(options=chrome_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "IsjYL7K_y1ip"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.imdb.com/title/tt1517268/reviews/?ref_=tt_ov_rt\"\n",
        "driver.get(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "XPGysdwuy190"
      },
      "outputs": [],
      "source": [
        "sel = Selector(text = driver.page_source)\n",
        "review_counts = sel.css('.lister .header span::text').extract_first().replace(',','').split(' ')[0]\n",
        "more_review_pages = int(int(review_counts)/25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGSJ0vuDy4D2",
        "outputId": "5bd75470-a74a-4b2c-ba76-a9025d71c79b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:00<00:00, 70.45it/s]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(more_review_pages)):\n",
        "    try:\n",
        "        css_selector = 'load-more-trigger'\n",
        "        driver.find_element(By.ID, css_selector).click()\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c46cAciBxr2C",
        "outputId": "d5a8737f-6162-434c-ef82-81317490960d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 160.91it/s]\n"
          ]
        }
      ],
      "source": [
        "rating_list = []\n",
        "review_date_list = []\n",
        "review_title_list = []\n",
        "author_list = []\n",
        "review_list = []\n",
        "review_url_list = []\n",
        "error_url_list = []\n",
        "error_msg_list = []\n",
        "reviews = driver.find_elements(By.CSS_SELECTOR, 'div.review-container')\n",
        "\n",
        "for d in tqdm(reviews):\n",
        "    try:\n",
        "        sel2 = Selector(text = d.get_attribute('innerHTML'))\n",
        "        try:\n",
        "            rating = sel2.css('.rating-other-user-rating span::text').extract_first()\n",
        "        except:\n",
        "            rating = np.NaN\n",
        "        try:\n",
        "            review = sel2.css('.text.show-more__control::text').extract_first()\n",
        "        except:\n",
        "            review = np.NaN\n",
        "        try:\n",
        "            review_date = sel2.css('.review-date::text').extract_first()\n",
        "        except:\n",
        "            review_date = np.NaN\n",
        "        try:\n",
        "            author = sel2.css('.display-name-link a::text').extract_first()\n",
        "        except:\n",
        "            author = np.NaN\n",
        "        try:\n",
        "            review_title = sel2.css('a.title::text').extract_first()\n",
        "        except:\n",
        "            review_title = np.NaN\n",
        "        try:\n",
        "            review_url = sel2.css('a.title::attr(href)').extract_first()\n",
        "        except:\n",
        "            review_url = np.NaN\n",
        "        rating_list.append(rating)\n",
        "        review_date_list.append(review_date)\n",
        "        review_title_list.append(review_title)\n",
        "        author_list.append(author)\n",
        "        review_list.append(review)\n",
        "        review_url_list.append(review_url)\n",
        "    except Exception as e:\n",
        "        error_url_list.append(url)\n",
        "        error_msg_list.append(e)\n",
        "review_df = pd.DataFrame({\n",
        "    'Review_Date':review_date_list,\n",
        "    'Author':author_list,\n",
        "    'Rating':rating_list,\n",
        "    'Review_Title':review_title_list,\n",
        "    'Review':review_list,\n",
        "    'Review_Url':review_url\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "W9A0C1tbyfuh",
        "outputId": "8a333f0d-5af6-42f0-f623-c35dbc3170bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review_Date</th>\n",
              "      <th>Author</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review_Title</th>\n",
              "      <th>Review</th>\n",
              "      <th>Review_Url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21 July 2023</td>\n",
              "      <td>LoveofLegacy</td>\n",
              "      <td>6</td>\n",
              "      <td>Beautiful film, but so preachy\\n</td>\n",
              "      <td>Margot does the best with what she's given, bu...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26 July 2023</td>\n",
              "      <td>aherdofbeautifulwildponies</td>\n",
              "      <td>6</td>\n",
              "      <td>A Hot Pink Mess\\n</td>\n",
              "      <td>Before making Barbie (2023),</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22 July 2023</td>\n",
              "      <td>imseeg</td>\n",
              "      <td>7</td>\n",
              "      <td>3 reasons FOR seeing it and 1 reason AGAINST.\\n</td>\n",
              "      <td>The first reason to go see it:</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31 July 2023</td>\n",
              "      <td>ramair350</td>\n",
              "      <td>10</td>\n",
              "      <td>As a guy I felt some discomfort, and that's o...</td>\n",
              "      <td>As much as it pains me to give a movie called ...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22 July 2023</td>\n",
              "      <td>Natcat87</td>\n",
              "      <td>6</td>\n",
              "      <td>Too heavy handed\\n</td>\n",
              "      <td>As a woman that grew up with Barbie, I was ver...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20 July 2023</td>\n",
              "      <td>Azureus91</td>\n",
              "      <td>None</td>\n",
              "      <td>I fee sorry to those who fell in the Barbenhe...</td>\n",
              "      <td>To say that I was disappointed is an understat...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>21 July 2023</td>\n",
              "      <td>Sleepin_Dragon</td>\n",
              "      <td>8</td>\n",
              "      <td>Well this really did come as a surprise.\\n</td>\n",
              "      <td>It pains me to say it, but I enjoyed this movi...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>21 July 2023</td>\n",
              "      <td>G-Joshua-Benjamin</td>\n",
              "      <td>6</td>\n",
              "      <td>My mom and I saw this yesterday. Here are my ...</td>\n",
              "      <td>I don't know if I put spoilers in here. I am s...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>24 July 2023</td>\n",
              "      <td>coxaneesa</td>\n",
              "      <td>8</td>\n",
              "      <td>It was depressing\\n</td>\n",
              "      <td>I thought this would be so much different. The...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20 July 2023</td>\n",
              "      <td>portraitofaladyonfire</td>\n",
              "      <td>6</td>\n",
              "      <td>Brilliant observations, but social depth is m...</td>\n",
              "      <td>Greta Gerwig and Noah Baumbach have a knack fo...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20 July 2023</td>\n",
              "      <td>MissSimonetta</td>\n",
              "      <td>4</td>\n",
              "      <td>The marketing was more entertaining than the ...</td>\n",
              "      <td>I went to see this today, everyone in my group...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>19 July 2023</td>\n",
              "      <td>HabibieHakim123</td>\n",
              "      <td>8</td>\n",
              "      <td>Barbie Is A Weirdly Fun Movie!\\n</td>\n",
              "      <td>8.5/10\\nWhile i'm not so sure at first, the mo...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>23 July 2023</td>\n",
              "      <td>Revuer223</td>\n",
              "      <td>6</td>\n",
              "      <td>Could Have Been Great. 2nd Half Brings It Dow...</td>\n",
              "      <td>The quality, the humor, and the writing of the...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>29 August 2023</td>\n",
              "      <td>antoniatejedabarros</td>\n",
              "      <td>3</td>\n",
              "      <td>Disappointing: terribly preachy and horrendou...</td>\n",
              "      <td>Margot Robbie and Ryan Gosling are really grea...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>24 July 2023</td>\n",
              "      <td>heatherhilgers</td>\n",
              "      <td>9</td>\n",
              "      <td>A Technicolor Dream\\n</td>\n",
              "      <td>Wow, this movie was a love letter to cinema. F...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>27 August 2023</td>\n",
              "      <td>kayleewillis-85920</td>\n",
              "      <td>6</td>\n",
              "      <td>OVERHYPED\\n</td>\n",
              "      <td>This is a movie that was way overhyped. Everyo...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>19 July 2023</td>\n",
              "      <td>jpismyname</td>\n",
              "      <td>8</td>\n",
              "      <td>Fun and surprisingly touching\\n</td>\n",
              "      <td>I was honestly doubting this movie at first, b...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>24 July 2023</td>\n",
              "      <td>lokicola</td>\n",
              "      <td>6</td>\n",
              "      <td>Strong Start... and That's It\\n</td>\n",
              "      <td>I walked out of the theatre thinking, \"Yeah, I...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>9 August 2023</td>\n",
              "      <td>L3MM3</td>\n",
              "      <td>None</td>\n",
              "      <td>Boring, mind-numbing drivel\\n</td>\n",
              "      <td>I do not usually write reviews, but this is be...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>22 July 2023</td>\n",
              "      <td>finnconnelly-63017</td>\n",
              "      <td>10</td>\n",
              "      <td>Ken out of ten\\n</td>\n",
              "      <td>Wow. I did not see this masterpiece coming. An...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>19 July 2023</td>\n",
              "      <td>hamsterination</td>\n",
              "      <td>6</td>\n",
              "      <td>It could have been so much better...\\n</td>\n",
              "      <td>The film's universe and settings are fantastic...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3 August 2023</td>\n",
              "      <td>AngelHonesty</td>\n",
              "      <td>5</td>\n",
              "      <td>Not what I Expected\\n</td>\n",
              "      <td>I played with barbies a lot as a kid, so I tho...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>20 July 2023</td>\n",
              "      <td>Genti25</td>\n",
              "      <td>8</td>\n",
              "      <td>You are Kenough\\n</td>\n",
              "      <td>This movie is so much fun. It starts off reall...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>20 July 2023</td>\n",
              "      <td>fscsgxp</td>\n",
              "      <td>6</td>\n",
              "      <td>Amazing Cast &amp; Set, but the political message...</td>\n",
              "      <td>I've been excited for this movie for over a ye...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>23 July 2023</td>\n",
              "      <td>herrcarter-92161</td>\n",
              "      <td>5</td>\n",
              "      <td>Somewhat of a Jumbled Mess\\n</td>\n",
              "      <td>My 15-year old daughter wrote the following re...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1 August 2023</td>\n",
              "      <td>zkonedog</td>\n",
              "      <td>10</td>\n",
              "      <td>An Amazingly Perfect Blend Of Social Satire &amp;...</td>\n",
              "      <td>For a film like \"Barbie\" to succeed, every asp...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>29 July 2023</td>\n",
              "      <td>planktonrules</td>\n",
              "      <td>6</td>\n",
              "      <td>Good...not great\\n</td>\n",
              "      <td>\"Barbie\" is a movie that is setting all sorts ...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>4 August 2023</td>\n",
              "      <td>thePopcornExplorer</td>\n",
              "      <td>9</td>\n",
              "      <td>I don't see how it was preachy\\n</td>\n",
              "      <td>In this day and age with society overall becom...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>21 July 2023</td>\n",
              "      <td>andermic18</td>\n",
              "      <td>6</td>\n",
              "      <td>No Direction\\n</td>\n",
              "      <td>The movie was very funny and really enjoyable ...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>19 July 2023</td>\n",
              "      <td>andypaps101</td>\n",
              "      <td>8</td>\n",
              "      <td>\"Barbie\" - A Multifaceted Exploration of Femi...</td>\n",
              "      <td>I got free tickets for a preview and to be hon...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>19 July 2023</td>\n",
              "      <td>tm-sheehan</td>\n",
              "      <td>6</td>\n",
              "      <td>Didn't hit my pink spot\\n</td>\n",
              "      <td>My Review - Barbie\\nIn Cinemas now\\nMy Rating ...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>27 August 2023</td>\n",
              "      <td>max-850</td>\n",
              "      <td>4</td>\n",
              "      <td>Preacher Barbie?\\n</td>\n",
              "      <td>I believe I came to this movie with an open mi...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>29 July 2023</td>\n",
              "      <td>cmdown-50506</td>\n",
              "      <td>9</td>\n",
              "      <td>Now I am become Barbie Girl, the enjoyer of B...</td>\n",
              "      <td>I have been waiting for this to release for so...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>24 July 2023</td>\n",
              "      <td>GhostFoxX</td>\n",
              "      <td>6</td>\n",
              "      <td>Misleading.\\n</td>\n",
              "      <td>I personally expected the movie to be fun and ...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>24 July 2023</td>\n",
              "      <td>brianjohnson-20043</td>\n",
              "      <td>4</td>\n",
              "      <td>This movie tries to be too much\\n</td>\n",
              "      <td>I wanted to like it. But I just didn't. The st...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>21 July 2023</td>\n",
              "      <td>masonsaul</td>\n",
              "      <td>10</td>\n",
              "      <td>The best version of itself\\n</td>\n",
              "      <td>Barbie is everything expected of it and so muc...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>15 September 2023</td>\n",
              "      <td>maxlagerholm</td>\n",
              "      <td>6</td>\n",
              "      <td>Excellent marketing team.\\n</td>\n",
              "      <td>They really did some fantastic marketing with ...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>21 July 2023</td>\n",
              "      <td>imdbmovieguy</td>\n",
              "      <td>None</td>\n",
              "      <td>Honestly - not funny and light enough\\n</td>\n",
              "      <td>I really enjoyed the first 20 minutes of the m...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>19 July 2023</td>\n",
              "      <td>anjamulder</td>\n",
              "      <td>8</td>\n",
              "      <td>not for everyone\\n</td>\n",
              "      <td>This is very much a movie that will get devide...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>19 July 2023</td>\n",
              "      <td>mark-217-307033</td>\n",
              "      <td>6</td>\n",
              "      <td>Fun film whose script falls in on itself\\n</td>\n",
              "      <td>Margot Robbie's performance is perfect, and no...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>23 July 2023</td>\n",
              "      <td>eoinageary</td>\n",
              "      <td>8</td>\n",
              "      <td>I am Kenough\\n</td>\n",
              "      <td>So I went into the movie with little to no exp...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>21 July 2023</td>\n",
              "      <td>arslanmanzoor123</td>\n",
              "      <td>6</td>\n",
              "      <td>Quite disappointing\\n</td>\n",
              "      <td>Some friends freaking out that I went to see B...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>21 July 2023</td>\n",
              "      <td>MaskedMinty</td>\n",
              "      <td>5</td>\n",
              "      <td>Preach Preach Preach\\n</td>\n",
              "      <td>Let me start by saying that I'm by no means a ...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>23 July 2023</td>\n",
              "      <td>subxerogravity</td>\n",
              "      <td>8</td>\n",
              "      <td>It's like G.I Joe...For girls! Seriously, and...</td>\n",
              "      <td>I mean, Margo Robbie as Barbie just made perfe...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>19 July 2023</td>\n",
              "      <td>AvionPrince16</td>\n",
              "      <td>6</td>\n",
              "      <td>Barbie land and reality\\n</td>\n",
              "      <td>Im not really disappointed or love the movie t...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>25 July 2023</td>\n",
              "      <td>Dello_</td>\n",
              "      <td>4</td>\n",
              "      <td>Funny and sharp first half, boring and baffli...</td>\n",
              "      <td>I had great expectations for the Barbie movie,...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>21 July 2023</td>\n",
              "      <td>rannynm</td>\n",
              "      <td>10</td>\n",
              "      <td>What A Film! I Was Ecstatic About Seeing Barb...</td>\n",
              "      <td>What a film! I was ecstatic about seeing Barbi...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>25 July 2023</td>\n",
              "      <td>spika13</td>\n",
              "      <td>6</td>\n",
              "      <td>Too overrated\\n</td>\n",
              "      <td>Its like watching at \"Truman's show\" but all t...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>23 July 2023</td>\n",
              "      <td>Anurag-Shetty</td>\n",
              "      <td>10</td>\n",
              "      <td>A wholesome delight!\\n</td>\n",
              "      <td>Barbie is based on Mattel's iconic plastic dol...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>19 July 2023</td>\n",
              "      <td>dreopdreef</td>\n",
              "      <td>6</td>\n",
              "      <td>Not so unique as expected\\n</td>\n",
              "      <td>The concept of a Barbie movie is really unique...</td>\n",
              "      <td>/review/rw9201199/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Review_Date                      Author Rating  \\\n",
              "0        21 July 2023                LoveofLegacy      6   \n",
              "1        26 July 2023  aherdofbeautifulwildponies      6   \n",
              "2        22 July 2023                      imseeg      7   \n",
              "3        31 July 2023                   ramair350     10   \n",
              "4        22 July 2023                    Natcat87      6   \n",
              "5        20 July 2023                   Azureus91   None   \n",
              "6        21 July 2023              Sleepin_Dragon      8   \n",
              "7        21 July 2023           G-Joshua-Benjamin      6   \n",
              "8        24 July 2023                   coxaneesa      8   \n",
              "9        20 July 2023       portraitofaladyonfire      6   \n",
              "10       20 July 2023               MissSimonetta      4   \n",
              "11       19 July 2023             HabibieHakim123      8   \n",
              "12       23 July 2023                   Revuer223      6   \n",
              "13     29 August 2023         antoniatejedabarros      3   \n",
              "14       24 July 2023              heatherhilgers      9   \n",
              "15     27 August 2023          kayleewillis-85920      6   \n",
              "16       19 July 2023                  jpismyname      8   \n",
              "17       24 July 2023                    lokicola      6   \n",
              "18      9 August 2023                       L3MM3   None   \n",
              "19       22 July 2023          finnconnelly-63017     10   \n",
              "20       19 July 2023              hamsterination      6   \n",
              "21      3 August 2023                AngelHonesty      5   \n",
              "22       20 July 2023                     Genti25      8   \n",
              "23       20 July 2023                     fscsgxp      6   \n",
              "24       23 July 2023            herrcarter-92161      5   \n",
              "25      1 August 2023                    zkonedog     10   \n",
              "26       29 July 2023               planktonrules      6   \n",
              "27      4 August 2023          thePopcornExplorer      9   \n",
              "28       21 July 2023                  andermic18      6   \n",
              "29       19 July 2023                 andypaps101      8   \n",
              "30       19 July 2023                  tm-sheehan      6   \n",
              "31     27 August 2023                     max-850      4   \n",
              "32       29 July 2023                cmdown-50506      9   \n",
              "33       24 July 2023                   GhostFoxX      6   \n",
              "34       24 July 2023          brianjohnson-20043      4   \n",
              "35       21 July 2023                   masonsaul     10   \n",
              "36  15 September 2023                maxlagerholm      6   \n",
              "37       21 July 2023                imdbmovieguy   None   \n",
              "38       19 July 2023                  anjamulder      8   \n",
              "39       19 July 2023             mark-217-307033      6   \n",
              "40       23 July 2023                  eoinageary      8   \n",
              "41       21 July 2023            arslanmanzoor123      6   \n",
              "42       21 July 2023                 MaskedMinty      5   \n",
              "43       23 July 2023              subxerogravity      8   \n",
              "44       19 July 2023               AvionPrince16      6   \n",
              "45       25 July 2023                      Dello_      4   \n",
              "46       21 July 2023                     rannynm     10   \n",
              "47       25 July 2023                     spika13      6   \n",
              "48       23 July 2023               Anurag-Shetty     10   \n",
              "49       19 July 2023                  dreopdreef      6   \n",
              "\n",
              "                                         Review_Title  \\\n",
              "0                    Beautiful film, but so preachy\\n   \n",
              "1                                   A Hot Pink Mess\\n   \n",
              "2     3 reasons FOR seeing it and 1 reason AGAINST.\\n   \n",
              "3    As a guy I felt some discomfort, and that's o...   \n",
              "4                                  Too heavy handed\\n   \n",
              "5    I fee sorry to those who fell in the Barbenhe...   \n",
              "6          Well this really did come as a surprise.\\n   \n",
              "7    My mom and I saw this yesterday. Here are my ...   \n",
              "8                                 It was depressing\\n   \n",
              "9    Brilliant observations, but social depth is m...   \n",
              "10   The marketing was more entertaining than the ...   \n",
              "11                   Barbie Is A Weirdly Fun Movie!\\n   \n",
              "12   Could Have Been Great. 2nd Half Brings It Dow...   \n",
              "13   Disappointing: terribly preachy and horrendou...   \n",
              "14                              A Technicolor Dream\\n   \n",
              "15                                        OVERHYPED\\n   \n",
              "16                    Fun and surprisingly touching\\n   \n",
              "17                    Strong Start... and That's It\\n   \n",
              "18                      Boring, mind-numbing drivel\\n   \n",
              "19                                   Ken out of ten\\n   \n",
              "20             It could have been so much better...\\n   \n",
              "21                              Not what I Expected\\n   \n",
              "22                                  You are Kenough\\n   \n",
              "23   Amazing Cast & Set, but the political message...   \n",
              "24                       Somewhat of a Jumbled Mess\\n   \n",
              "25   An Amazingly Perfect Blend Of Social Satire &...   \n",
              "26                                 Good...not great\\n   \n",
              "27                   I don't see how it was preachy\\n   \n",
              "28                                     No Direction\\n   \n",
              "29   \"Barbie\" - A Multifaceted Exploration of Femi...   \n",
              "30                          Didn't hit my pink spot\\n   \n",
              "31                                 Preacher Barbie?\\n   \n",
              "32   Now I am become Barbie Girl, the enjoyer of B...   \n",
              "33                                      Misleading.\\n   \n",
              "34                  This movie tries to be too much\\n   \n",
              "35                       The best version of itself\\n   \n",
              "36                        Excellent marketing team.\\n   \n",
              "37            Honestly - not funny and light enough\\n   \n",
              "38                                 not for everyone\\n   \n",
              "39         Fun film whose script falls in on itself\\n   \n",
              "40                                     I am Kenough\\n   \n",
              "41                              Quite disappointing\\n   \n",
              "42                             Preach Preach Preach\\n   \n",
              "43   It's like G.I Joe...For girls! Seriously, and...   \n",
              "44                          Barbie land and reality\\n   \n",
              "45   Funny and sharp first half, boring and baffli...   \n",
              "46   What A Film! I Was Ecstatic About Seeing Barb...   \n",
              "47                                    Too overrated\\n   \n",
              "48                             A wholesome delight!\\n   \n",
              "49                        Not so unique as expected\\n   \n",
              "\n",
              "                                               Review  \\\n",
              "0   Margot does the best with what she's given, bu...   \n",
              "1                       Before making Barbie (2023),    \n",
              "2                      The first reason to go see it:   \n",
              "3   As much as it pains me to give a movie called ...   \n",
              "4   As a woman that grew up with Barbie, I was ver...   \n",
              "5   To say that I was disappointed is an understat...   \n",
              "6   It pains me to say it, but I enjoyed this movi...   \n",
              "7   I don't know if I put spoilers in here. I am s...   \n",
              "8   I thought this would be so much different. The...   \n",
              "9   Greta Gerwig and Noah Baumbach have a knack fo...   \n",
              "10  I went to see this today, everyone in my group...   \n",
              "11  8.5/10\\nWhile i'm not so sure at first, the mo...   \n",
              "12  The quality, the humor, and the writing of the...   \n",
              "13  Margot Robbie and Ryan Gosling are really grea...   \n",
              "14  Wow, this movie was a love letter to cinema. F...   \n",
              "15  This is a movie that was way overhyped. Everyo...   \n",
              "16  I was honestly doubting this movie at first, b...   \n",
              "17  I walked out of the theatre thinking, \"Yeah, I...   \n",
              "18  I do not usually write reviews, but this is be...   \n",
              "19  Wow. I did not see this masterpiece coming. An...   \n",
              "20  The film's universe and settings are fantastic...   \n",
              "21  I played with barbies a lot as a kid, so I tho...   \n",
              "22  This movie is so much fun. It starts off reall...   \n",
              "23  I've been excited for this movie for over a ye...   \n",
              "24  My 15-year old daughter wrote the following re...   \n",
              "25  For a film like \"Barbie\" to succeed, every asp...   \n",
              "26  \"Barbie\" is a movie that is setting all sorts ...   \n",
              "27  In this day and age with society overall becom...   \n",
              "28  The movie was very funny and really enjoyable ...   \n",
              "29  I got free tickets for a preview and to be hon...   \n",
              "30  My Review - Barbie\\nIn Cinemas now\\nMy Rating ...   \n",
              "31  I believe I came to this movie with an open mi...   \n",
              "32  I have been waiting for this to release for so...   \n",
              "33  I personally expected the movie to be fun and ...   \n",
              "34  I wanted to like it. But I just didn't. The st...   \n",
              "35  Barbie is everything expected of it and so muc...   \n",
              "36  They really did some fantastic marketing with ...   \n",
              "37  I really enjoyed the first 20 minutes of the m...   \n",
              "38  This is very much a movie that will get devide...   \n",
              "39  Margot Robbie's performance is perfect, and no...   \n",
              "40  So I went into the movie with little to no exp...   \n",
              "41  Some friends freaking out that I went to see B...   \n",
              "42  Let me start by saying that I'm by no means a ...   \n",
              "43  I mean, Margo Robbie as Barbie just made perfe...   \n",
              "44  Im not really disappointed or love the movie t...   \n",
              "45  I had great expectations for the Barbie movie,...   \n",
              "46  What a film! I was ecstatic about seeing Barbi...   \n",
              "47  Its like watching at \"Truman's show\" but all t...   \n",
              "48  Barbie is based on Mattel's iconic plastic dol...   \n",
              "49  The concept of a Barbie movie is really unique...   \n",
              "\n",
              "                        Review_Url  \n",
              "0   /review/rw9201199/?ref_=tt_urv  \n",
              "1   /review/rw9201199/?ref_=tt_urv  \n",
              "2   /review/rw9201199/?ref_=tt_urv  \n",
              "3   /review/rw9201199/?ref_=tt_urv  \n",
              "4   /review/rw9201199/?ref_=tt_urv  \n",
              "5   /review/rw9201199/?ref_=tt_urv  \n",
              "6   /review/rw9201199/?ref_=tt_urv  \n",
              "7   /review/rw9201199/?ref_=tt_urv  \n",
              "8   /review/rw9201199/?ref_=tt_urv  \n",
              "9   /review/rw9201199/?ref_=tt_urv  \n",
              "10  /review/rw9201199/?ref_=tt_urv  \n",
              "11  /review/rw9201199/?ref_=tt_urv  \n",
              "12  /review/rw9201199/?ref_=tt_urv  \n",
              "13  /review/rw9201199/?ref_=tt_urv  \n",
              "14  /review/rw9201199/?ref_=tt_urv  \n",
              "15  /review/rw9201199/?ref_=tt_urv  \n",
              "16  /review/rw9201199/?ref_=tt_urv  \n",
              "17  /review/rw9201199/?ref_=tt_urv  \n",
              "18  /review/rw9201199/?ref_=tt_urv  \n",
              "19  /review/rw9201199/?ref_=tt_urv  \n",
              "20  /review/rw9201199/?ref_=tt_urv  \n",
              "21  /review/rw9201199/?ref_=tt_urv  \n",
              "22  /review/rw9201199/?ref_=tt_urv  \n",
              "23  /review/rw9201199/?ref_=tt_urv  \n",
              "24  /review/rw9201199/?ref_=tt_urv  \n",
              "25  /review/rw9201199/?ref_=tt_urv  \n",
              "26  /review/rw9201199/?ref_=tt_urv  \n",
              "27  /review/rw9201199/?ref_=tt_urv  \n",
              "28  /review/rw9201199/?ref_=tt_urv  \n",
              "29  /review/rw9201199/?ref_=tt_urv  \n",
              "30  /review/rw9201199/?ref_=tt_urv  \n",
              "31  /review/rw9201199/?ref_=tt_urv  \n",
              "32  /review/rw9201199/?ref_=tt_urv  \n",
              "33  /review/rw9201199/?ref_=tt_urv  \n",
              "34  /review/rw9201199/?ref_=tt_urv  \n",
              "35  /review/rw9201199/?ref_=tt_urv  \n",
              "36  /review/rw9201199/?ref_=tt_urv  \n",
              "37  /review/rw9201199/?ref_=tt_urv  \n",
              "38  /review/rw9201199/?ref_=tt_urv  \n",
              "39  /review/rw9201199/?ref_=tt_urv  \n",
              "40  /review/rw9201199/?ref_=tt_urv  \n",
              "41  /review/rw9201199/?ref_=tt_urv  \n",
              "42  /review/rw9201199/?ref_=tt_urv  \n",
              "43  /review/rw9201199/?ref_=tt_urv  \n",
              "44  /review/rw9201199/?ref_=tt_urv  \n",
              "45  /review/rw9201199/?ref_=tt_urv  \n",
              "46  /review/rw9201199/?ref_=tt_urv  \n",
              "47  /review/rw9201199/?ref_=tt_urv  \n",
              "48  /review/rw9201199/?ref_=tt_urv  \n",
              "49  /review/rw9201199/?ref_=tt_urv  "
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "review_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gHLLYflzw_f"
      },
      "source": [
        "Let's save this `pd.DataFrame` as a `.csv` to our local session (this will be terminated when you terminate the Colab session) so we can leverage it in LangChain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "N9FDhwbNz64p"
      },
      "outputs": [],
      "source": [
        "review_df.to_csv(\"./barbie.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = review_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=pd.read_csv(\"../data/barbie.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtBD1H8ezNLO"
      },
      "source": [
        "#### Data Parsing\n",
        "\n",
        "Now that we have our data - let's go ahead and set up some tools to parse it into a more usable format for LangChain!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CTameZZ0r76"
      },
      "source": [
        "Our reviews might contain a lot of information, and in order to ensure they don't exceed the context window of our model and to allow us to include a few reviews as context for each query - let's construct a system to \"chunk\" our data into smaller pieces.\n",
        "\n",
        "We'll be leveraging the `RecursiveCharacterTextSplitter` for this task today.\n",
        "\n",
        "While splitting our text seems like a simple enough task - getting this correct/incorrect can have massive downstream impacts on your application's performance.\n",
        "\n",
        "You can read the docs here:\n",
        "- [RecursiveCharacterTextSplitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter)\n",
        "\n",
        "> ### HINT:\n",
        ">It's always worth it to check out the LangChain source code if you're ever in a bind - for instance, if you want to know how to transform a set of documents, check it out [here](https://github.com/langchain-ai/langchain/blob/5e9687a196410e9f41ebcd11eb3f2ca13925545b/libs/langchain/langchain/text_splitter.py#L268C18-L268C18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "uEgcUVtl00Xm"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000, # the character length of the chunk\n",
        "    chunk_overlap = 100, # the character length of the overlap between chunks\n",
        "    length_function = len, # the length function - in this case, character length (aka the python len() fn.)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylT4jwmx3zCb"
      },
      "source": [
        "Now that we have our `RecursiveCharacterTextSplitter` set up - let's look at how it might split our source text. \n",
        "\n",
        "Keep in mind that the source text is split by `[\"\\n\\n\", \"\\n\", \" \", \"\"]` in that order.\n",
        "\n",
        "We know that each of the subheadings in our review `page_content` is separated by a newline character, so it will preferably chunk the review subheadings together. \n",
        "\n",
        "That's great! Let's move on to creating our index!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cB0L_CN38W5"
      },
      "source": [
        "### Task 2: Creating an \"Index\"\n",
        "\n",
        "The term \"index\" is used largely to mean: Structured documents parsed into a useful format for querying, retrieving, and use in the LLM application stack."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GycdG53N4f9Z"
      },
      "source": [
        "#### Selecting Our VectorStore\n",
        "\n",
        "There are a number of different VectorStores, and a number of different strengths and weaknesses to each.\n",
        "\n",
        "In this notebook, we will be keeping it very simple by leveraging Pinecone's API Vector Database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5o4vwSn4hfe",
        "outputId": "62bf250d-1c4f-49c3-b154-71e52d530ddf"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's set up a Pinecone index using the methods provided in their [documentation](https://docs.pinecone.io/docs/langchain)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pinecone\n",
        "\n",
        "YOUR_API_KEY = os.environ[\"PINECONE_API_KEY\"]\n",
        "YOUR_ENV = os.environ[\"PINECONE_ENV\"]\n",
        "\n",
        "index_name = 'barbie-review-index'\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=YOUR_API_KEY,\n",
        "    environment=YOUR_ENV\n",
        ")\n",
        "\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    # we create a new index\n",
        "    pinecone.create_index(\n",
        "        name=index_name,\n",
        "        metric='cosine',\n",
        "        dimension=1536\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can connect to our index and view some statistics about it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.00234,\n",
              " 'namespaces': {'': {'vector_count': 234}},\n",
              " 'total_vector_count': 234}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index = pinecone.GRPCIndex(index_name)\n",
        "\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGU96p5R54Xz"
      },
      "source": [
        "We're going to be setting up our VectorStore with the OpenAI embeddings model. While this embeddings model does not need to be consistent with the LLM selection, it does need to be consistent between embedding our index and embedding our queries over that index.\n",
        "\n",
        "While we don't have to worry too much about that in this example - it's something to keep in mind for more complex applications.\n",
        "\n",
        "We're going to leverage a [`CacheBackedEmbeddings`](https://python.langchain.com/docs/modules/data_connection/caching_embeddings )flow to prevent us from re-embedding similar queries over and over again.\n",
        "\n",
        "Not only will this save time, it will also save us precious embedding tokens, which will reduce the overall cost for our application.\n",
        "\n",
        ">#### Note:\n",
        ">The overall cost savings needs to be compared against the additional cost of storing the cached embeddings for a true cost/benefit analysis. If your users are submitting the same queries often, though, this pattern can be a massive reduction in cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "AOzZWPU05WLr"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "from langchain.storage import LocalFileStore\n",
        "\n",
        "store = LocalFileStore(\"./cache/\")\n",
        "\n",
        "core_embeddings_model = OpenAIEmbeddings()\n",
        "\n",
        "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    core_embeddings_model, store, namespace=core_embeddings_model.model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have our `CacheBackedEmbeddings` pipeline set-up, let's index our documents into our Pinecone Vector Database. \n",
        "\n",
        "We'll add some useful metadata as well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Review_Date</th>\n",
              "      <th>Author</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review_Title</th>\n",
              "      <th>Review</th>\n",
              "      <th>Review_Url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>21 July 2023</td>\n",
              "      <td>LoveofLegacy</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Beautiful film, but so preachy\\n</td>\n",
              "      <td>Margot does the best with what she's given, bu...</td>\n",
              "      <td>/review/rw9221648/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   Review_Date        Author  Rating  \\\n",
              "0           0  21 July 2023  LoveofLegacy     6.0   \n",
              "\n",
              "                        Review_Title  \\\n",
              "0   Beautiful film, but so preachy\\n   \n",
              "\n",
              "                                              Review  \\\n",
              "0  Margot does the best with what she's given, bu...   \n",
              "\n",
              "                       Review_Url  \n",
              "0  /review/rw9221648/?ref_=tt_urv  "
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 195.43it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from uuid import uuid4\n",
        "\n",
        "BATCH_LIMIT = 100\n",
        "\n",
        "texts = []\n",
        "metadatas = []\n",
        "\n",
        "for i in tqdm(range(len(data))):\n",
        "\n",
        "    record = data.iloc[i]\n",
        "\n",
        "    metadata = {\n",
        "        'review-url': str(record[\"Review_Url\"]),\n",
        "        'review-date' : str(record[\"Review_Date\"]),\n",
        "        'author' : str(record[\"Author\"]),\n",
        "        'rating' : str(record[\"Rating\"]),\n",
        "        'review-title' : str(record[\"Review_Title\"]),\n",
        "    }\n",
        "\n",
        "    record_texts = text_splitter.split_text(record[\"Review\"])\n",
        "\n",
        "    record_metadatas = [{\n",
        "        \"chunk\": j, \"text\": text, **metadata\n",
        "    } for j, text in enumerate(record_texts)]\n",
        "    texts.extend(record_texts)\n",
        "    metadatas.extend(record_metadatas)\n",
        "    if len(texts) >= BATCH_LIMIT:\n",
        "        ids = [str(uuid4()) for _ in range(len(texts))]\n",
        "        embeds = embedder.embed_documents(texts)\n",
        "        index.upsert(vectors=zip(ids, embeds, metadatas))\n",
        "        texts = []\n",
        "        metadatas = []\n",
        "\n",
        "if len(texts) > 0:\n",
        "    ids = [str(uuid4()) for _ in range(len(texts))]\n",
        "    embeds = embedder.embed_documents(texts)\n",
        "    index.upsert(vectors=zip(ids, embeds, metadatas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.00234,\n",
              " 'namespaces': {'': {'vector_count': 234}},\n",
              " 'total_vector_count': 234}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we've created our index, let's convert it to a LangChain `VectorStroe` so we can use it in the rest of the LangChain ecosystem!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "text_field = \"text\"\n",
        "\n",
        "index = pinecone.Index(index_name)\n",
        "\n",
        "vectorstore = Pinecone(\n",
        "    index, embedder.embed_query, text_field\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGHzcE5i6fOR"
      },
      "source": [
        "Now that we've created the VectorStore, we can check that it's working by embedding a query and retrieving passages from our reviews that are close to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content=\"The film's universe and settings are fantastic. The casting is really good too, with Gosling excelling in the role of Ken.\", metadata={'author': 'hamsterination', 'chunk': 0.0, 'rating': '6.0', 'review-date': datetime.datetime(2023, 7, 19, 0, 0), 'review-title': ' It could have been so much better...\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'}),\n",
              " Document(page_content=\"The film's universe and settings are fantastic. The casting is really good too, with Gosling excelling in the role of Ken.\", metadata={'author': 'hamsterination', 'chunk': 0.0, 'rating': '6.0', 'review-date': datetime.datetime(2023, 7, 19, 0, 0), 'review-title': ' It could have been so much better...\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'}),\n",
              " Document(page_content='This movie is so much fun. It starts off really strong although the story does move away from \"Barbieland\" sooner than I would have liked. Nonetheless, it regains its footing with the final act in particular and I could not stop laughing at Ryan Gosling\\'s portrayal of Ken. That song will forever be stuck in my head.', metadata={'author': 'Genti25', 'chunk': 0.0, 'rating': '8.0', 'review-date': datetime.datetime(2023, 7, 20, 0, 0), 'review-title': ' You are Kenough\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'})]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"Who played Ken?\"\n",
        "\n",
        "vectorstore.similarity_search(\n",
        "    query, \n",
        "    k=3  \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4fyOUS-fU-"
      },
      "source": [
        "Let's see how much time the `CacheBackedEmbeddings` pattern saves us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCwtsJbc_KPd",
        "outputId": "92acfeb8-26e8-4dd8-d247-29fea2ca5187"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The slowest run took 74.44 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "17 s Â± 7.48 s per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "query = \"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow.\"\n",
        "vectorstore.similarity_search(\n",
        "    query, \n",
        "    k=3  \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4utL1EfARTm"
      },
      "source": [
        "As we can see, even over a significant number of runs - the cached query is significantly faster than the first instance of the query!\n",
        "\n",
        "With that, we're ready to move onto Task 3!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po3kHNHGBp0j"
      },
      "source": [
        "### Task 3: Building a Retrieval Chain\n",
        "\n",
        "In this task, we'll be making a Retrieval Chain which will allow us to ask semantic questions over our data.\n",
        "\n",
        "This part is rather abstracted away from us in LangChain and so it seems very powerful.\n",
        "\n",
        "Be sure to check the documentation, the source code, and other provided resources to build a deeper understanding of what's happening \"under the hood\"!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5Ux9XdzCDi9"
      },
      "source": [
        "#### A Basic RetrievalQA Chain\n",
        "\n",
        "We're going to leverage `return_source_documents=True` to ensure we have proper sources for our reviews - should the end user want to verify the reviews themselves.\n",
        "\n",
        "Hallucinations [are](https://arxiv.org/abs/2202.03629) [a](https://arxiv.org/abs/2305.15852) [massive](https://arxiv.org/abs/2303.16104) [problem](https://arxiv.org/abs/2305.18248) in LLM applications.\n",
        "\n",
        "Though it has been tenuously shown that using Retrieval Augmentation [reduces hallucination in conversations](https://arxiv.org/pdf/2104.07567.pdf), one sure fire way to ensure your model is not hallucinating in a non-transparent way is to provide sources with your responses. This way the end-user can verify the output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_waVo3AEk71"
      },
      "source": [
        "#### Our LLM\n",
        "\n",
        "In this notebook, we'll continue to leverage OpenAI's suite of models - this time we'll be using the `gpt-3.5-turbo` model to power our RetrievalQAWithSources chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "QfglvbBtExPR"
      },
      "outputs": [],
      "source": [
        "from langchain.llms.openai import OpenAIChat\n",
        "\n",
        "llm = OpenAIChat(model=\"gpt-3.5-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w35ZkVEoE8II"
      },
      "source": [
        "Now we can set up our chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "T8TWJMH8F_w7"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "QeD8R6huFIf6"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "\n",
        "handler = StdOutCallbackHandler()\n",
        "\n",
        "qa_with_sources_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    callbacks=[handler],\n",
        "    return_source_documents=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqPaII9nF72R",
        "outputId": "0b46128f-edbe-4010-afdc-36603f25c4c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Will Ferrell ruined every scene he was in.'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_with_sources_chain({\"query\" : \"How was Will Ferrell in this movie?\"})[\"result\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47Ov7N22MxOS",
        "outputId": "aeb6271b-4161-4921-e07c-b5f9041e9c4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Based on the given context, it is unclear whether reviewers consider this movie \"Kenough\" or not.'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})[\"result\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the available metadata we have, thanks to our index-creation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "result = qa_with_sources_chain({\"query\" : \"Was Will Ferrel funny?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Key: query\n",
            "Value: Was Will Ferrel funny?\n",
            "\n",
            "Key: result\n",
            "Value: No, the person states that Will Ferrell ruined every scene he was in.\n",
            "\n",
            "Key: source_documents\n",
            "Value: [Document(page_content=\"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\", metadata={'author': 'agjbull', 'chunk': 0.0, 'rating': '6.0', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Just a little empty\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'}), Document(page_content=\"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\", metadata={'author': 'agjbull', 'chunk': 0.0, 'rating': '6.0', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Just a little empty\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'}), Document(page_content=\"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\", metadata={'author': 'agjbull', 'chunk': 0.0, 'rating': '6.0', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Just a little empty\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'}), Document(page_content=\"The quality, the humor, and the writing of the movie is fun for a while. It's quirky and it's unique. When they get into the weeds and try to explore deeper themes, the movie is a miss. The middle expositional phase of the movie, I must say, is a bore.\", metadata={'author': 'Revuer223', 'chunk': 0.0, 'rating': '6.0', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Could Have Been Great. 2nd Half Brings It Down.\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'})]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for k, v in result.items():\n",
        "    print(f\"Key: {k}\")\n",
        "    print(f\"Value: {v}\")\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metadata: ('metadata', {'author': 'agjbull', 'chunk': 0.0, 'rating': '6.0', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Just a little empty\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'})\n",
            "Page Content: ('page_content', \"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\")\n",
            "\n",
            "Metadata: ('metadata', {'author': 'agjbull', 'chunk': 0.0, 'rating': '6.0', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Just a little empty\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'})\n",
            "Page Content: ('page_content', \"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\")\n",
            "\n",
            "Metadata: ('metadata', {'author': 'agjbull', 'chunk': 0.0, 'rating': '6.0', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Just a little empty\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'})\n",
            "Page Content: ('page_content', \"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\")\n",
            "\n",
            "Metadata: ('metadata', {'author': 'Revuer223', 'chunk': 0.0, 'rating': '6.0', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Could Have Been Great. 2nd Half Brings It Down.\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'})\n",
            "Page Content: ('page_content', \"The quality, the humor, and the writing of the movie is fun for a while. It's quirky and it's unique. When they get into the weeds and try to explore deeper themes, the movie is a miss. The middle expositional phase of the movie, I must say, is a bore.\")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for page_content, metadata in result[\"source_documents\"]:\n",
        "    print(f\"Metadata: {metadata}\")\n",
        "    print(f\"Page Content: {page_content}\")\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding Prompt Caching and Monitoring\n",
        "\n",
        "Now that we have the basic `RetrievalQAChain` set up and working - let's add a few more tools to help us built a more performant application and add a visibility tool as well!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Visibility Tooling\n",
        "\n",
        "We'll be once again leveraging Weights and Biases as our visibility tool, so let's add that first!\n",
        "\n",
        "You'll want to use the same Weights and Biases account that you set-up last Thursday here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_API_KEY\"] = getpass.getpass(\"Weights and Biases API Key:\")\n",
        "os.environ[\"WANDB_PROJECT\"] = \"barbie-retrieval-qa\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, to set up WandB, all we have to do is..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Yes, that's it. \n",
        "\n",
        "Let's use our `RetrievalQA` chain to test it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Based on the given context, it is unclear whether reviewers consider this movie \"Kenough\" or not.'"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})[\"result\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With those simple lines of code - we've added full visibility to our prompts and responses through Weights and Biases! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prompt Caching\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding A Prompt Cache\n",
        "\n",
        "The basic idea of Prompt Caching is to provide a way to circumvent going to the LLM for prompts we have already seen.\n",
        "\n",
        "Similar to cached embeddings, the idea is simple:\n",
        "\n",
        "- Keep track of all the input/output pairs\n",
        "- If a user query is (in the case of semantic similarity caches) close enough to a previous prompt contained in the cache, return the output associated with that pair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initializing a Prompt Cache\n",
        "\n",
        "There are many different tools you can use to implement a Prompt Cache - from a \"build it yourself\" VectorStore implementation - to Redis - to custom libraries - there are upsides and downsides to each solution. \n",
        "\n",
        "Let's look at the Redis-backed Cache vs. `InMemoryCache` as an example:\n",
        "\n",
        "Redis Cache\n",
        "| Pros  | Cons  |\n",
        "|---|---|\n",
        "| Managed and Robust  | Expensive to Host  |\n",
        "| Integrations on all Major Cloud Platforms  | Non-trivial to Integrate |\n",
        "| Easily Scalable  | Does not have a ChatModel implementation |\n",
        "\n",
        "`InMemoryCache`\n",
        "| Pros  | Cons  |\n",
        "|---|---|\n",
        "| Easily implemented  | Consumes potentially precious memory |\n",
        "| Completely Cloud Agnostic  | Does not offer inter-session caching |\n",
        "\n",
        "For the sake of ease of use - and to allow functionality with our `ChatOpenAI` model - we'll leverage `InMemoryCache`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to set our `langchain.llm_cache` to use the `InMemoryCache`.\n",
        "\n",
        "- [`InMemoryCache`](https://api.python.langchain.com/en/latest/cache/langchain.cache.InMemoryCache.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "import langchain\n",
        "from langchain.cache import InMemoryCache\n",
        "langchain.llm_cache = InMemoryCache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One more important fact about the `InMemoryCache` is that it is what's called an \"exact-match\" cache - meaning it will only trigger when the user query is *exactly* represented in the cache. \n",
        "\n",
        "This is a safer cache, as we can guarentee the user's query exactly matches with previous queries and we don't have to worry about edge-cases where semantic similarity might fail - but it does reduce the potential to hit the cache.\n",
        "\n",
        "We could leverage tools like `GPTCache`, or `RedisCache` (for non-chat model implementations) to get a \"semantic similarity\" cache, if desired!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "CPU times: user 16.9 ms, sys: 2.62 ms, total: 19.5 ms\n",
            "Wall time: 2.03 s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Based on the given context, it is unclear whether reviewers consider this movie \"Kenough\" or not.'"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})[\"result\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "CPU times: user 12.4 ms, sys: 2.06 ms, total: 14.5 ms\n",
            "Wall time: 250 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Based on the given context, it is unclear whether reviewers consider this movie \"Kenough\" or not.'"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})[\"result\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at an example that is extremely close - but is not the exact query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 10.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Skipping trace saving - unable to safely convert LangChain Run into W&B Trace due to: 'NoneType' object has no attribute 'items'\n"
          ]
        },
        {
          "ename": "RateLimitError",
          "evalue": "Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "File \u001b[0;32m<timed eval>:1\u001b[0m\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/chains/base.py:312\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 312\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    313\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    314\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    315\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    316\u001b[0m )\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/chains/base.py:306\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    299\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    300\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    301\u001b[0m     inputs,\n\u001b[1;32m    302\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    303\u001b[0m )\n\u001b[1;32m    304\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 306\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    307\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    308\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py:136\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    132\u001b[0m accepts_run_manager \u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs)\u001b[39m.\u001b[39mparameters\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m accepts_run_manager:\n\u001b[0;32m--> 136\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_docs(question, run_manager\u001b[39m=\u001b[39;49m_run_manager)\n\u001b[1;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs(question)  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py:216\u001b[0m, in \u001b[0;36mRetrievalQA._get_docs\u001b[0;34m(self, question, run_manager)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_docs\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     question: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    212\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m    213\u001b[0m     run_manager: CallbackManagerForChainRun,\n\u001b[1;32m    214\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m    215\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get docs.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretriever\u001b[39m.\u001b[39;49mget_relevant_documents(\n\u001b[1;32m    217\u001b[0m         question, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child()\n\u001b[1;32m    218\u001b[0m     )\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/schema/retriever.py:212\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    211\u001b[0m     run_manager\u001b[39m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    213\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     run_manager\u001b[39m.\u001b[39mon_retriever_end(\n\u001b[1;32m    215\u001b[0m         result,\n\u001b[1;32m    216\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    217\u001b[0m     )\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/schema/retriever.py:205\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m _kwargs \u001b[39m=\u001b[39m kwargs \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expects_other_args \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 205\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_relevant_documents(\n\u001b[1;32m    206\u001b[0m         query, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_kwargs\n\u001b[1;32m    207\u001b[0m     )\n\u001b[1;32m    208\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_relevant_documents(query, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs)\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/schema/vectorstore.py:565\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_relevant_documents\u001b[39m(\n\u001b[1;32m    562\u001b[0m     \u001b[39mself\u001b[39m, query: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[1;32m    563\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m    564\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 565\u001b[0m         docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectorstore\u001b[39m.\u001b[39;49msimilarity_search(query, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearch_kwargs)\n\u001b[1;32m    566\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msimilarity_score_threshold\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    567\u001b[0m         docs_and_similarities \u001b[39m=\u001b[39m (\n\u001b[1;32m    568\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorstore\u001b[39m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[1;32m    569\u001b[0m                 query, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_kwargs\n\u001b[1;32m    570\u001b[0m             )\n\u001b[1;32m    571\u001b[0m         )\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/vectorstores/pinecone.py:226\u001b[0m, in \u001b[0;36mPinecone.similarity_search\u001b[0;34m(self, query, k, filter, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_search\u001b[39m(\n\u001b[1;32m    208\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    209\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    214\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m    215\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return pinecone documents most similar to query.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \n\u001b[1;32m    217\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     docs_and_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimilarity_search_with_score(\n\u001b[1;32m    227\u001b[0m         query, k\u001b[39m=\u001b[39;49mk, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m, namespace\u001b[39m=\u001b[39;49mnamespace, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    229\u001b[0m     \u001b[39mreturn\u001b[39;00m [doc \u001b[39mfor\u001b[39;00m doc, _ \u001b[39min\u001b[39;00m docs_and_scores]\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/vectorstores/pinecone.py:172\u001b[0m, in \u001b[0;36mPinecone.similarity_search_with_score\u001b[0;34m(self, query, k, filter, namespace)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_search_with_score\u001b[39m(\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    155\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m     namespace: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    159\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Tuple[Document, \u001b[39mfloat\u001b[39m]]:\n\u001b[1;32m    160\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return pinecone documents most similar to query, along with scores.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[1;32m    162\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimilarity_search_by_vector_with_score(\n\u001b[0;32m--> 172\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed_query(query), k\u001b[39m=\u001b[39mk, \u001b[39mfilter\u001b[39m\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m, namespace\u001b[39m=\u001b[39mnamespace\n\u001b[1;32m    173\u001b[0m     )\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/vectorstores/pinecone.py:91\u001b[0m, in \u001b[0;36mPinecone._embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding, Embeddings):\n\u001b[1;32m     90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding\u001b[39m.\u001b[39membed_query(text)\n\u001b[0;32m---> 91\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding(text)\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/embeddings/cache.py:147\u001b[0m, in \u001b[0;36mCacheBackedEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_query\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Embed query text.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[1;32m    132\u001b[0m \u001b[39m    This method does not support caching at the moment.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m        The embedding for the given text.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munderlying_embeddings\u001b[39m.\u001b[39;49membed_query(text)\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/embeddings/openai.py:518\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_query\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m    510\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \n\u001b[1;32m    512\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[39m        Embedding for the text.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_documents([text])[\u001b[39m0\u001b[39m]\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/embeddings/openai.py:490\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \n\u001b[1;32m    480\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/embeddings/openai.py:374\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    371\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[1;32m    373\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[0;32m--> 374\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[1;32m    375\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    376\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[1;32m    377\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[1;32m    378\u001b[0m     )\n\u001b[1;32m    379\u001b[0m     batched_embeddings\u001b[39m.\u001b[39mextend(r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    381\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/embeddings/openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/tenacity/__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m     retry_exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[0;32m--> 325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/tenacity/__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreraise\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mNoReturn:\n\u001b[1;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_attempt\u001b[39m.\u001b[39mfailed:\n\u001b[0;32m--> 158\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_attempt\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/langchain/embeddings/openai.py:104\u001b[0m, in \u001b[0;36membed_with_retry.<locals>._embed_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
            "File \u001b[0;32m~/.virtualenvs/llm/lib/python3.11/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for default-text-embedding-ada-002 in organization org-Cdg8XtIG3WjRFquQiNg6yWVc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method."
          ]
        }
      ],
      "source": [
        "%%time\n",
        "qa_with_sources_chain({\"query\" : \"Do reviewers consider this here movie Kenough?\"})[\"result\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, adding an exact-match prompt cache is a very small lift - but it can significantly improve the latency of your end-user application experience!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQVCkoy3H5Rw"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "And with that, we have our Barbie Review RAQA Application built!\n",
        "\n",
        "Let's port it into a Chainlit app and put it up on a Hugging Face Space!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOiWOWtcIc3OpL6fUrMAdOt",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
